{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SQIrbZo60IqB"
      },
      "source": [
        "### **Data Preparation for Image Classification**\n",
        "\n",
        "We'll demonstrate how to prepare image data for a classification task using Python and Pandas. Specifically, we'll:\n",
        "\n",
        "1.   **Load image data from CSV files.**\n",
        "2.   **Split the data into train, validation, and test sets.**\n",
        "3.   **Organize the data into directories suitable for training a machine learning model.**\n",
        "\n",
        "\n",
        "Let's get started by loading the necessary libraries and reading the CSV files containing image paths and corresponding labels. We'll then split the data and organize it into appropriate directories. Finally, we'll copy the images to their respective directories, readying them for model training.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E8k3qVaGz6BG"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import csv\n",
        "import shutil\n",
        "from sklearn.model_selection import train_test_split\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Reading the train.csv and test.csv\n",
        "train = pd.read_csv('./dataset/train.csv')\n",
        "test = pd.read_csv('./dataset/test.csv')\n",
        "print(\"Data loaded successfully.\")\n",
        "print(f\"Train shape: {train.shape}, Test shape: {test.shape}\")\n",
        "print(\"Label distribution in train data:\", train['label'].value_counts())\n",
        "\n",
        "# Paths\n",
        "train_dir = \"./dataset/train\"\n",
        "test_dir = \"./dataset/test\"\n",
        "csv_file = './dataset/train.csv'\n",
        "output_dir = './dataset/'\n",
        "\n",
        "# Read CSV file and prepare data list\n",
        "data = []\n",
        "with open(csv_file, 'r') as f:\n",
        "    reader = csv.reader(f)\n",
        "    next(reader)  # Skip header\n",
        "    for row in reader:\n",
        "        image_path, class_name = row\n",
        "        data.append((train_dir + '/' + image_path, class_name))\n",
        "print(\"Data list prepared from CSV.\")\n",
        "\n",
        "# Split the data into train, validation, and test sets\n",
        "train_data, test_data = train_test_split(data, test_size=0.2, random_state=42)\n",
        "train_data, valid_data = train_test_split(train_data, test_size=0.1, random_state=42)\n",
        "print(\"Data split into train, validation, and test sets.\")\n",
        "\n",
        "# Create output directories for the datasets\n",
        "for dataset, data_items in [('train', train_data), ('val', valid_data), ('test', test_data)]:\n",
        "    dataset_dir = os.path.join(output_dir, dataset)\n",
        "    os.makedirs(dataset_dir, exist_ok=True)\n",
        "    for _, class_name in data_items:\n",
        "        class_dir = os.path.join(dataset_dir, class_name)\n",
        "        os.makedirs(class_dir, exist_ok=True)\n",
        "    print(f\"Created directories for {dataset} dataset.\")\n",
        "\n",
        "# Copy images to respective class folders in train, validation, and test sets\n",
        "for dataset, data_items in [('train', train_data), ('val', valid_data), ('test', test_data)]:\n",
        "    for image_path, class_name in data_items:\n",
        "        source_path = image_path\n",
        "        destination_path = os.path.join(output_dir, dataset, class_name, os.path.basename(image_path))\n",
        "        shutil.copy(source_path, destination_path)\n",
        "    print(f\"Images copied to {dataset} dataset directory.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zIFkF2mA4fZ1"
      },
      "source": [
        "### **Training and Evaluating YOLO Model on Custom Dataset**\n",
        "\n",
        "This code snippet outlines the process of training and evaluating a YOLO (You Only Look Once) model on a custom dataset for object detection tasks. YOLO is a popular deep learning algorithm known for its real-time object detection capabilities."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OmW3sh9m4iv_"
      },
      "outputs": [],
      "source": [
        "# Import YOLO model\n",
        "from ultralytics import YOLO\n",
        "\n",
        "# Define class dictionary\n",
        "class_dict = {0: 'Badminton', 1: 'Cricket', 2: 'Karate', 3: 'Soccer', 4: 'Swimming', 5: 'Tennis', 6: 'Wrestling'}\n",
        "\n",
        "# Load a pre-trained YOLOv8 model\n",
        "model = YOLO('yolov8n-cls.pt')  # Load a pre-trained model\n",
        "\n",
        "# Fine-tune the model on a custom dataset\n",
        "result = model.train(data='./dataset/', epochs=1, imgsz=64)\n",
        "\n",
        "# Evaluate the model on the test dataset\n",
        "# eval_result = model.eval(data='G:/Disk D/NUCES Fast/Semester 6/AI/Final Project/code/dataset/test')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SUb1uFKu0H3h"
      },
      "source": [
        "### **Visualizing Training Results in Colab**\n",
        "\n",
        "We'll demonstrate how to visualize training results, specifically loss and validation accuracy, using matplotlib in Google Colab.\n",
        "\n",
        "We first load the training results from a CSV file, typically generated during model training. Then, we plot the training loss and validation loss against epochs to understand how the model's performance evolves over time. Additionally, we plot the validation accuracy against epochs to observe the model's learning progress.\n",
        "\n",
        "These visualizations provide insights into the training process, helping to assess the model's performance and identify potential areas for improvement. By analyzing these plots, researchers and practitioners can make informed decisions about model optimization and tuning strategies."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sQyHAFEq1i24"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "results_path = './runs/classify/train9/results.csv'\n",
        "\n",
        "results = pd.read_csv(results_path)\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(results['                  epoch'], results['             train/loss'], label='train loss')\n",
        "plt.plot(results['                  epoch'], results['               val/loss'], label='val loss', c='red')\n",
        "plt.grid()\n",
        "plt.title('Loss vs epochs')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epochs')\n",
        "plt.legend()\n",
        "\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(results['                  epoch'], results['  metrics/accuracy_top1'] * 100)\n",
        "plt.grid()\n",
        "plt.title('Validation accuracy vs epochs')\n",
        "plt.ylabel('accuracy (%)')\n",
        "plt.xlabel('epochs')\n",
        "\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CuK80gat2my7"
      },
      "source": [
        "### **Testing at my end**\n",
        "\n",
        "The provided code snippet demonstrates how to use the Ultralytics library to perform object detection using a custom YOLO (You Only Look Once) model.\n",
        "\n",
        "1. **Importing Libraries:**\n",
        "   - The `ultralytics` library is imported to utilize its YOLO object detection capabilities.\n",
        "   - `torch` and `numpy` libraries are imported for general tensor and array manipulation.\n",
        "\n",
        "2. **Loading the Model:**\n",
        "   - The YOLO model is loaded using the `YOLO` class from the Ultralytics library. The path to the custom model weights (`last.pt`) is provided as an argument.\n",
        "\n",
        "3. **Performing Object Detection:**\n",
        "   - The `model` object is called with an image path (`'./pexels-case-originals-3800517.jpg'`) to perform object detection on that image.\n",
        "   - The results of the detection are stored in the `results` variable.\n",
        "\n",
        "4. **Extracting Prediction Results:**\n",
        "   - The `results` object contains detection results such as bounding boxes, labels, and confidence scores.\n",
        "   - The `names_dict` variable holds a dictionary mapping class indices to class names.\n",
        "   - The `probs` variable stores the confidence scores for each detected object class.\n",
        "   - The class with the highest confidence score is determined using `np.argmax(probs)` and printed out.\n",
        "\n",
        "This code snippet provides a basic example of how to use a custom YOLO model for object detection and extract prediction results from the model's output."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f67dwWnq3KZ7"
      },
      "outputs": [],
      "source": [
        "from ultralytics import YOLO\n",
        "import torch\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "model = YOLO('./runs/classify/train9/weights/last.pt')  # load a custom model\n",
        "\n",
        "# model.eval()\n",
        "\n",
        "results = model('./pexels-case-originals-3800517.jpg')  # predict on an image\n",
        "\n",
        "# print(results)\n",
        "\n",
        "names_dict = results[0].names\n",
        "\n",
        "probs = results[0].probs.data.tolist()\n",
        "\n",
        "print(names_dict)\n",
        "print(probs)\n",
        "\n",
        "print(names_dict[np.argmax(probs)])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a-Yy0rCe3OhY"
      },
      "source": [
        "### **Object Detection API Backend with Flask and Ultralytics YOLO**\n",
        "\n",
        "This code sets up a Flask backend for an object detection API using the Ultralytics YOLO model. The purpose is to create a RESTful API endpoint (`/predict`) that accepts POST requests containing images, processes them using the YOLO model, and returns the predicted class based on the highest confidence score.\n",
        "\n",
        "The backend is built using Flask, a lightweight web application framework for Python, and leverages the Ultralytics YOLO model for object detection tasks. Additionally, the Flask-CORS extension is used to enable cross-origin resource sharing, allowing requests from different origins.\n",
        "\n",
        "The `/predict` endpoint handles incoming image files, checks their format, converts them to the required RGB format if necessary, and then performs object detection using the YOLO model. Finally, it extracts the prediction results and returns the predicted class along with its confidence score as a JSON response.\n",
        "\n",
        "This backend provides a simple yet powerful solution for integrating object detection capabilities into web applications, allowing developers to easily deploy and serve machine learning models for real-world applications."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KSn3KImt3-Ai"
      },
      "outputs": [],
      "source": [
        "from flask import Flask, request, jsonify\n",
        "from ultralytics import YOLO\n",
        "from PIL import Image\n",
        "from flask_cors import CORS\n",
        "import io\n",
        "\n",
        "app = Flask(__name__)\n",
        "CORS(app)\n",
        "model = YOLO('./runs/classify/train9/weights/last.pt')\n",
        "\n",
        "@app.route('/predict', methods=['POST'])\n",
        "def predict():\n",
        "    if 'image' not in request.files:\n",
        "        return jsonify({'error': 'No image provided'})\n",
        "\n",
        "    file = request.files['image']\n",
        "    image_bytes = file.read()\n",
        "\n",
        "    try:\n",
        "        # Open image using PIL to check format and convert to supported format\n",
        "        image = Image.open(io.BytesIO(image_bytes))\n",
        "\n",
        "        # Convert image to RGB format (if not already in RGB)\n",
        "        if image.mode != 'RGB':\n",
        "            image = image.convert('RGB')\n",
        "\n",
        "        # Process the image with the Ultralytics model\n",
        "        results = model(image)\n",
        "\n",
        "        # Extract prediction results and return\n",
        "        names_dict = results[0].names\n",
        "        probs = results[0].probs.data.tolist()\n",
        "        predicted_class = names_dict[probs.index(max(probs))]\n",
        "\n",
        "        return jsonify({'predicted_class': predicted_class})\n",
        "    except Exception as e:\n",
        "        return jsonify({'error': str(e)})\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    app.run(debug=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}

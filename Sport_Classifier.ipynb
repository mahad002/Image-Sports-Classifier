{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SQIrbZo60IqB"
      },
      "source": [
        "### **Data Preparation for Image Classification**\n",
        "\n",
        "We'll demonstrate how to prepare image data for a classification task using Python and Pandas. Specifically, we'll:\n",
        "\n",
        "1.   **Load image data from CSV files.**\n",
        "2.   **Split the data into train, validation, and test sets.**\n",
        "3.   **Organize the data into directories suitable for training a machine learning model.**\n",
        "\n",
        "\n",
        "Let's get started by loading the necessary libraries and reading the CSV files containing image paths and corresponding labels. We'll then split the data and organize it into appropriate directories. Finally, we'll copy the images to their respective directories, readying them for model training.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "E8k3qVaGz6BG"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Data loaded successfully.\n",
            "Train shape: (8227, 2), Test shape: (2056, 1)\n",
            "Label distribution in train data: label\n",
            "Cricket      1556\n",
            "Wrestling    1471\n",
            "Tennis       1445\n",
            "Badminton    1394\n",
            "Soccer       1188\n",
            "Swimming      595\n",
            "Karate        578\n",
            "Name: count, dtype: int64\n",
            "Data list prepared from CSV.\n",
            "Data split into train, validation, and test sets.\n",
            "Created directories for train dataset.\n",
            "Created directories for val dataset.\n",
            "Created directories for test dataset.\n",
            "Images copied to train dataset directory.\n",
            "Images copied to val dataset directory.\n",
            "Images copied to test dataset directory.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import csv\n",
        "import shutil\n",
        "from sklearn.model_selection import train_test_split\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Reading the train.csv and test.csv\n",
        "train = pd.read_csv('./dataset/train.csv')\n",
        "test = pd.read_csv('./dataset/test.csv')\n",
        "print(\"Data loaded successfully.\")\n",
        "print(f\"Train shape: {train.shape}, Test shape: {test.shape}\")\n",
        "print(\"Label distribution in train data:\", train['label'].value_counts())\n",
        "\n",
        "# Paths\n",
        "train_dir = \"./dataset/train\"\n",
        "test_dir = \"./dataset/test\"\n",
        "csv_file = './dataset/train.csv'\n",
        "output_dir = './dataset/'\n",
        "\n",
        "# Read CSV file and prepare data list\n",
        "data = []\n",
        "with open(csv_file, 'r') as f:\n",
        "    reader = csv.reader(f)\n",
        "    next(reader)  # Skip header\n",
        "    for row in reader:\n",
        "        image_path, class_name = row\n",
        "        data.append((train_dir + '/' + image_path, class_name))\n",
        "print(\"Data list prepared from CSV.\")\n",
        "\n",
        "# Split the data into train, validation, and test sets\n",
        "train_data, test_data = train_test_split(data, test_size=0.2, random_state=42)\n",
        "train_data, valid_data = train_test_split(train_data, test_size=0.1, random_state=42)\n",
        "print(\"Data split into train, validation, and test sets.\")\n",
        "\n",
        "# Create output directories for the datasets\n",
        "for dataset, data_items in [('train', train_data), ('val', valid_data), ('test', test_data)]:\n",
        "    dataset_dir = os.path.join(output_dir, dataset)\n",
        "    os.makedirs(dataset_dir, exist_ok=True)\n",
        "    for _, class_name in data_items:\n",
        "        class_dir = os.path.join(dataset_dir, class_name)\n",
        "        os.makedirs(class_dir, exist_ok=True)\n",
        "    print(f\"Created directories for {dataset} dataset.\")\n",
        "\n",
        "# Copy images to respective class folders in train, validation, and test sets\n",
        "for dataset, data_items in [('train', train_data), ('val', valid_data), ('test', test_data)]:\n",
        "    for image_path, class_name in data_items:\n",
        "        source_path = image_path\n",
        "        destination_path = os.path.join(output_dir, dataset, class_name, os.path.basename(image_path))\n",
        "        shutil.copy(source_path, destination_path)\n",
        "    print(f\"Images copied to {dataset} dataset directory.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zIFkF2mA4fZ1"
      },
      "source": [
        "### **Training and Evaluating YOLO Model on Custom Dataset**\n",
        "\n",
        "This code snippet outlines the process of training and evaluating a YOLO (You Only Look Once) model on a custom dataset for object detection tasks. YOLO is a popular deep learning algorithm known for its real-time object detection capabilities."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "OmW3sh9m4iv_"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "New https://pypi.org/project/ultralytics/8.2.9 available  Update with 'pip install -U ultralytics'\n",
            "Ultralytics YOLOv8.2.7  Python-3.12.3 torch-2.3.0+cpu CPU (11th Gen Intel Core(TM) i7-11850H 2.50GHz)\n",
            "\u001b[34m\u001b[1mengine\\trainer: \u001b[0mtask=classify, mode=train, model=yolov8n-cls.pt, data=G:/Disk D/NUCES Fast/Semester 6/AI/Final Project/code/dataset/, epochs=1, time=None, patience=100, batch=16, imgsz=64, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train17, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs\\classify\\train17\n",
            "\u001b[34m\u001b[1mtrain:\u001b[0m G:\\Disk D\\NUCES Fast\\Semester 6\\AI\\Final Project\\code\\dataset\\train... found 14149 images in 8 classes: ERROR  requires 7 classes, not 8\n",
            "\u001b[34m\u001b[1mval:\u001b[0m G:\\Disk D\\NUCES Fast\\Semester 6\\AI\\Final Project\\code\\dataset\\val... found 659 images in 7 classes  \n",
            "\u001b[34m\u001b[1mtest:\u001b[0m G:\\Disk D\\NUCES Fast\\Semester 6\\AI\\Final Project\\code\\dataset\\test... found 3702 images in 8 classes: ERROR  requires 7 classes, not 8\n",
            "Overriding model.yaml nc=1000 with nc=7\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
            "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
            "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
            "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
            "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
            "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
            "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
            "  9                  -1  1    339207  ultralytics.nn.modules.head.Classify         [256, 7]                      \n",
            "YOLOv8n-cls summary: 99 layers, 1447255 parameters, 1447255 gradients, 3.4 GFLOPs\n",
            "Transferred 156/158 items from pretrained weights\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs\\classify\\train17', view at http://localhost:6006/\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning G:\\Disk D\\NUCES Fast\\Semester 6\\AI\\Final Project\\code\\dataset\\train... 5921 images, 1 corrupt: 100%|██████████| 5921/5921 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  G:\\Disk D\\NUCES Fast\\Semester 6\\AI\\Final Project\\code\\dataset\\train\\Cricket\\50b30fd5f8.jpg: ignoring corrupt image/label: image size (1, 1) <10 pixels\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning G:\\Disk D\\NUCES Fast\\Semester 6\\AI\\Final Project\\code\\dataset\\val... 659 images, 0 corrupt: 100%|██████████| 659/659 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000714, momentum=0.9) with parameter groups 26 weight(decay=0.0), 27 weight(decay=0.0005), 27 bias(decay=0.0)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added \n",
            "Image sizes 64 train, 64 val\n",
            "Using 0 dataloader workers\n",
            "Logging results to \u001b[1mruns\\classify\\train17\u001b[0m\n",
            "Starting training for 1 epochs...\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "        1/1         0G       1.68          1         64: 100%|██████████| 371/371 [01:45<00:00,  3.50it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 21/21 [00:08<00:00,  2.36it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all      0.636      0.974\n",
            "\n",
            "1 epochs completed in 0.033 hours.\n",
            "Optimizer stripped from runs\\classify\\train17\\weights\\last.pt, 3.0MB\n",
            "Optimizer stripped from runs\\classify\\train17\\weights\\best.pt, 3.0MB\n",
            "\n",
            "Validating runs\\classify\\train17\\weights\\best.pt...\n",
            "Ultralytics YOLOv8.2.7  Python-3.12.3 torch-2.3.0+cpu CPU (11th Gen Intel Core(TM) i7-11850H 2.50GHz)\n",
            "YOLOv8n-cls summary (fused): 73 layers, 1443847 parameters, 0 gradients, 3.3 GFLOPs\n",
            "\u001b[34m\u001b[1mtrain:\u001b[0m G:\\Disk D\\NUCES Fast\\Semester 6\\AI\\Final Project\\code\\dataset\\train... found 14149 images in 8 classes: ERROR  requires 7 classes, not 8\n",
            "\u001b[34m\u001b[1mval:\u001b[0m G:\\Disk D\\NUCES Fast\\Semester 6\\AI\\Final Project\\code\\dataset\\val... found 659 images in 7 classes  \n",
            "\u001b[34m\u001b[1mtest:\u001b[0m G:\\Disk D\\NUCES Fast\\Semester 6\\AI\\Final Project\\code\\dataset\\test... found 3702 images in 8 classes: ERROR  requires 7 classes, not 8\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "               classes   top1_acc   top5_acc: 100%|██████████| 21/21 [00:05<00:00,  4.18it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all      0.637      0.974\n",
            "Speed: 0.0ms preprocess, 0.5ms inference, 0.0ms loss, 0.0ms postprocess per image\n",
            "Results saved to \u001b[1mruns\\classify\\train17\u001b[0m\n",
            "Results saved to \u001b[1mruns\\classify\\train17\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "# Import YOLO model\n",
        "from ultralytics import YOLO\n",
        "\n",
        "# Define class dictionary\n",
        "class_dict = {0: 'Badminton', 1: 'Cricket', 2: 'Karate', 3: 'Soccer', 4: 'Swimming', 5: 'Tennis', 6: 'Wrestling'}\n",
        "\n",
        "# Load a pre-trained YOLOv8 model\n",
        "model = YOLO('yolov8n-cls.pt')  # Load a pre-trained model\n",
        "\n",
        "# Fine-tune the model on a custom dataset\n",
        "result = model.train(data='./dataset/', epochs=1, imgsz=64)\n",
        "\n",
        "# Evaluate the model on the test dataset\n",
        "# eval_result = model.eval(data='G:/Disk D/NUCES Fast/Semester 6/AI/Final Project/code/dataset/test')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SUb1uFKu0H3h"
      },
      "source": [
        "### **Visualizing Training Results in Colab**\n",
        "\n",
        "We'll demonstrate how to visualize training results, specifically loss and validation accuracy, using matplotlib in Google Colab.\n",
        "\n",
        "We first load the training results from a CSV file, typically generated during model training. Then, we plot the training loss and validation loss against epochs to understand how the model's performance evolves over time. Additionally, we plot the validation accuracy against epochs to observe the model's learning progress.\n",
        "\n",
        "These visualizations provide insights into the training process, helping to assess the model's performance and identify potential areas for improvement. By analyzing these plots, researchers and practitioners can make informed decisions about model optimization and tuning strategies."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "sQyHAFEq1i24"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "results_path = './runs/classify/train9/results.csv'\n",
        "\n",
        "results = pd.read_csv(results_path)\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(results['                  epoch'], results['             train/loss'], label='train loss')\n",
        "plt.plot(results['                  epoch'], results['               val/loss'], label='val loss', c='red')\n",
        "plt.grid()\n",
        "plt.title('Loss vs epochs')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epochs')\n",
        "plt.legend()\n",
        "\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(results['                  epoch'], results['  metrics/accuracy_top1'] * 100)\n",
        "plt.grid()\n",
        "plt.title('Validation accuracy vs epochs')\n",
        "plt.ylabel('accuracy (%)')\n",
        "plt.xlabel('epochs')\n",
        "\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CuK80gat2my7"
      },
      "source": [
        "### **Testing at my end**\n",
        "\n",
        "The provided code snippet demonstrates how to use the Ultralytics library to perform object detection using a custom YOLO (You Only Look Once) model.\n",
        "\n",
        "1. **Importing Libraries:**\n",
        "   - The `ultralytics` library is imported to utilize its YOLO object detection capabilities.\n",
        "   - `torch` and `numpy` libraries are imported for general tensor and array manipulation.\n",
        "\n",
        "2. **Loading the Model:**\n",
        "   - The YOLO model is loaded using the `YOLO` class from the Ultralytics library. The path to the custom model weights (`last.pt`) is provided as an argument.\n",
        "\n",
        "3. **Performing Object Detection:**\n",
        "   - The `model` object is called with an image path (`'./pexels-case-originals-3800517.jpg'`) to perform object detection on that image.\n",
        "   - The results of the detection are stored in the `results` variable.\n",
        "\n",
        "4. **Extracting Prediction Results:**\n",
        "   - The `results` object contains detection results such as bounding boxes, labels, and confidence scores.\n",
        "   - The `names_dict` variable holds a dictionary mapping class indices to class names.\n",
        "   - The `probs` variable stores the confidence scores for each detected object class.\n",
        "   - The class with the highest confidence score is determined using `np.argmax(probs)` and printed out.\n",
        "\n",
        "This code snippet provides a basic example of how to use a custom YOLO model for object detection and extract prediction results from the model's output."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "f67dwWnq3KZ7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "image 1/1 g:\\Disk D\\NUCES Fast\\Semester 6\\AI\\Final Project\\code\\pexels-case-originals-3800517.jpg: 64x64 Cricket 0.97, Tennis 0.02, Soccer 0.01, Badminton 0.00, Wrestling 0.00, 3.4ms\n",
            "Speed: 79.2ms preprocess, 3.4ms inference, 0.0ms postprocess per image at shape (1, 3, 64, 64)\n",
            "{0: 'Badminton', 1: 'Cricket', 2: 'Karate', 3: 'Soccer', 4: 'Swimming', 5: 'Tennis', 6: 'Wrestling'}\n",
            "[0.00036736135371029377, 0.9737083911895752, 0.00011130962229799479, 0.0096367709338665, 2.070622031169478e-06, 0.015995753929018974, 0.0001783140323823318]\n",
            "Cricket\n"
          ]
        }
      ],
      "source": [
        "from ultralytics import YOLO\n",
        "import torch\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "model = YOLO('./runs/classify/train9/weights/last.pt')  # load a custom model\n",
        "\n",
        "# model.eval()\n",
        "\n",
        "results = model('./pexels-case-originals-3800517.jpg')  # predict on an image\n",
        "\n",
        "# print(results)\n",
        "\n",
        "names_dict = results[0].names\n",
        "\n",
        "probs = results[0].probs.data.tolist()\n",
        "\n",
        "print(names_dict)\n",
        "print(probs)\n",
        "\n",
        "print(names_dict[np.argmax(probs)])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a-Yy0rCe3OhY"
      },
      "source": [
        "### **Object Detection API Backend with Flask and Ultralytics YOLO**\n",
        "\n",
        "This code sets up a Flask backend for an object detection API using the Ultralytics YOLO model. The purpose is to create a RESTful API endpoint (`/predict`) that accepts POST requests containing images, processes them using the YOLO model, and returns the predicted class based on the highest confidence score.\n",
        "\n",
        "The backend is built using Flask, a lightweight web application framework for Python, and leverages the Ultralytics YOLO model for object detection tasks. Additionally, the Flask-CORS extension is used to enable cross-origin resource sharing, allowing requests from different origins.\n",
        "\n",
        "The `/predict` endpoint handles incoming image files, checks their format, converts them to the required RGB format if necessary, and then performs object detection using the YOLO model. Finally, it extracts the prediction results and returns the predicted class along with its confidence score as a JSON response.\n",
        "\n",
        "This backend provides a simple yet powerful solution for integrating object detection capabilities into web applications, allowing developers to easily deploy and serve machine learning models for real-world applications."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "KSn3KImt3-Ai"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " * Serving Flask app '__main__'\n",
            " * Debug mode: on\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
            " * Running on http://127.0.0.1:5000\n",
            "Press CTRL+C to quit\n",
            " * Restarting with stat\n"
          ]
        },
        {
          "ename": "SystemExit",
          "evalue": "1",
          "output_type": "error",
          "traceback": [
            "An exception has occurred, use %tb to see the full traceback.\n",
            "\u001b[1;31mSystemExit\u001b[0m\u001b[1;31m:\u001b[0m 1\n"
          ]
        }
      ],
      "source": [
        "from flask import Flask, request, jsonify\n",
        "from ultralytics import YOLO\n",
        "from PIL import Image\n",
        "from flask_cors import CORS\n",
        "import io\n",
        "\n",
        "app = Flask(__name__)\n",
        "CORS(app)\n",
        "model = YOLO('./runs/classify/train9/weights/last.pt')\n",
        "\n",
        "@app.route('/predict', methods=['POST'])\n",
        "def predict():\n",
        "    if 'image' not in request.files:\n",
        "        return jsonify({'error': 'No image provided'})\n",
        "\n",
        "    file = request.files['image']\n",
        "    image_bytes = file.read()\n",
        "\n",
        "    try:\n",
        "        # Open image using PIL to check format and convert to supported format\n",
        "        image = Image.open(io.BytesIO(image_bytes))\n",
        "\n",
        "        # Convert image to RGB format (if not already in RGB)\n",
        "        if image.mode != 'RGB':\n",
        "            image = image.convert('RGB')\n",
        "\n",
        "        # Process the image with the Ultralytics model\n",
        "        results = model(image)\n",
        "\n",
        "        # Extract prediction results and return\n",
        "        names_dict = results[0].names\n",
        "        probs = results[0].probs.data.tolist()\n",
        "        predicted_class = names_dict[probs.index(max(probs))]\n",
        "\n",
        "        return jsonify({'predicted_class': predicted_class})\n",
        "    except Exception as e:\n",
        "        return jsonify({'error': str(e)})\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    app.run(debug=True)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
